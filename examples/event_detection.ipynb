{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import kruskal, sem\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "from synet.networks import HomogeneousNetwork, merge_networks\n",
    "from synet.measures import MixingEntropy, PathEntropy, PaintEntropy, AgentEntropy, OverlapParameter\n",
    "from synet.analysis import entropy_windows, alpha_eff\n",
    "from synet.visualization import plot_entropy_game\n",
    "from synet.networks.random import random_two_split_network\n",
    "from synet.config import measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1872631)\n",
    "n_inter_events=40\n",
    "n_events = 5000\n",
    "n_agents=100\n",
    "dt = 3*n_agents + 1\n",
    "n_sample=10\n",
    "n_networks = 300\n",
    "output_fp = \"event_detection.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = [random_network() for _ in range(n_networks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_peak(entropy):\n",
    "    entropy_max = np.max(entropy)\n",
    "    return round(np.mean(np.where(entropy==entropy_max)[0]))\n",
    "\n",
    "def benchmark_intervals(net, dt):\n",
    "    cur_event = 0\n",
    "    l_bounds = []\n",
    "    u_bounds = []\n",
    "    events = mix_events(net)\n",
    "    bench_events = []\n",
    "    for i_event in range(len(events)):\n",
    "        if events[i_event] <= dt//2 or events[i_event] >= net.n_events-dt//2:\n",
    "            continue\n",
    "        if i_event == 0:\n",
    "            lower_bound = 0\n",
    "        else:\n",
    "            lower_bound = (events[i_event] - events[i_event-1])//2 + events[i_event-1]\n",
    "        lower_bound = max(dt//2, lower_bound)\n",
    "        if i_event == len(events)-1:\n",
    "            upper_bound = net.n_events\n",
    "        else:\n",
    "            upper_bound = (events[i_event+1]- events[i_event])//2 + events[i_event]\n",
    "        upper_bound = min(net.n_events - dt//2, upper_bound)\n",
    "        l_bounds.append(lower_bound)\n",
    "        u_bounds.append(upper_bound)\n",
    "        bench_events.append(events[i_event])\n",
    "    return np.array((l_bounds, u_bounds)).T, np.array(bench_events)\n",
    "\n",
    "def detect_all_peaks(entropy, intervals):\n",
    "    peaks = []\n",
    "    for lower_bound, upper_bound in intervals:\n",
    "        peaks.append(lower_bound + detect_peak(entropy[lower_bound:upper_bound]))\n",
    "    return peaks\n",
    "\n",
    "def mix_events(net):\n",
    "    events = np.where(net.event_sources==2)[0]\n",
    "    cur_mix_events = []\n",
    "    for ev in events:\n",
    "        agents = net.participants[ev]\n",
    "        if np.all(agents<n_agents//2) or np.all(agents>=n_agents//2):\n",
    "            continue\n",
    "        cur_mix_events.append(ev)\n",
    "    return np.array(cur_mix_events, dtype=int)\n",
    "\n",
    "def average_event_error(measure, networks, dt):\n",
    "    entropy_t = measure.entropy_t(networks, dt, n_jobs=32)\n",
    "    avg_error = []\n",
    "    for i_net, net in enumerate(networks):\n",
    "        entropy = entropy_t[i_net]\n",
    "        intervals, events = benchmark_intervals(net, dt)\n",
    "        peaks = detect_all_peaks(entropy, intervals)\n",
    "        if len(peaks) > 0:\n",
    "            avg_error.append(np.mean(np.abs(peaks-events)))\n",
    "        else:\n",
    "            avg_error.append(np.nan)\n",
    "    return np.mean(avg_error), stats.sem(avg_error, nan_policy=\"omit\")\n",
    "\n",
    "def average_random_error(intervals, events):\n",
    "    avg_error = []\n",
    "    for i_event in range(len(intervals)):\n",
    "        errors = np.arange(intervals[i_event][0] - events[i_event], intervals[i_event][1] - events[i_event])\n",
    "        avg_error.append(np.mean(np.abs(errors)))\n",
    "    return np.mean(avg_error)\n",
    "\n",
    "def get_random_error(networks, dt):\n",
    "    all_err = []\n",
    "    for net in networks:\n",
    "        intervals, events = benchmark_intervals(net, dt)\n",
    "        all_err.append(average_random_error(intervals, events))\n",
    "    return np.mean(all_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(networks):\n",
    "    all_dt = np.arange(n_agents//4, n_agents*3, n_agents//10)\n",
    "    all_dt[all_dt %2 == 0] += 1\n",
    "    df = pd.DataFrame()\n",
    "    df[\"dt\"] = all_dt\n",
    "    for measure_name, measure_class in measures.items():\n",
    "        err = []\n",
    "        sem = []\n",
    "        xvals = []\n",
    "        measure = measure_class()\n",
    "        for i_dt, dt in enumerate(all_dt):\n",
    "            if (dt % 2) == 0:\n",
    "                dt += 1\n",
    "            xvals.append(dt)\n",
    "            avg_error, avg_sem = average_event_error(measure, networks, dt)\n",
    "            err.append(avg_error)\n",
    "            sem.append(avg_sem)\n",
    "        df[measure_name] = err\n",
    "        df[measure_name+\"_err\"] = sem\n",
    "\n",
    "    df[\"random\"] = [get_random_error(networks, dt) for dt in all_dt]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, measure_names):\n",
    "    random = df[\"random\"].values\n",
    "    dt = df[\"dt\"].values\n",
    "    for name in measure_names:\n",
    "        err = df[name].values\n",
    "        sem = df[name+\"_err\"].values\n",
    "        plt.errorbar(dt, 1-err/random, sem/random, label=name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(output_fp)\n",
    "except FileNotFoundError:\n",
    "    df = create_dataframe(networks)\n",
    "    df.to_csv(output_fp, index=False)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plot_data(df, list(measures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"event_detection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix_events = np.sort(np.where(net.event_sources==2)[0])\n",
    "# iso_events = []\n",
    "# plt.figure(dpi=150)\n",
    "# plt.ylim(200, 270)\n",
    "# plt.grid()\n",
    "# for i_event in range(len(mix_events)):\n",
    "#     if i_event > 0 and mix_events[i_event]-mix_events[i_event-1] < dt:\n",
    "#         continue\n",
    "#     if i_event < len(mix_events)-1 and mix_events[i_event+1]-mix_events[i_event] < dt:\n",
    "#         continue\n",
    "#     iso_events.append(mix_events[i_event])\n",
    "#     start = mix_events[i_event]-dt//2 -1\n",
    "#     end = mix_events[i_event] + dt//2 +1\n",
    "#     plt.plot(entropy_t[start:end+1])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rate_intern = [10, 20, 50, 100]\n",
    "path_kruskal = []\n",
    "mix_kruskal = []\n",
    "path_error = []\n",
    "mix_error = []\n",
    "\n",
    "for rate_intern in all_rate_intern:\n",
    "    cur_d_mix = []\n",
    "    cur_d_path = []\n",
    "    for _ in range(n_sample):\n",
    "        A, event_list, event_participants = create_temporal_network(n_events=n_events, rate_intern=rate_intern)\n",
    "\n",
    "        eq_start = n_events//10\n",
    "        eq_end = 9*n_events//10\n",
    "\n",
    "        close_mixing = np.zeros(n_events, dtype=int)\n",
    "        for event in event_list[2]:\n",
    "            start = max(0, event - dt//2)\n",
    "            end = min(n_events-1, event + dt//2)\n",
    "            close_mixing[start:end] = 1\n",
    "        close_mixing[:eq_start] = -1\n",
    "        close_mixing[eq_end:] = -1\n",
    "        mix_idx = np.where(close_mixing == 1)[0]\n",
    "        separate_idx = np.where(close_mixing == 0)[0]\n",
    "\n",
    "\n",
    "        paint_t = entropy_windows(A, dt=dt, entropy_game=paint_entropy)\n",
    "        path_t = entropy_windows(A, dt=dt, entropy_game=path_entropy)\n",
    "        mixing_t = entropy_windows(A, dt=dt, entropy_game=mixing_entropy)\n",
    "\n",
    "        cur_paint = kruskal(\n",
    "            paint_t[mix_idx], paint_t[separate_idx], nan_policy=\"omit\"\n",
    "        ).statistic\n",
    "        cur_path = kruskal(\n",
    "            path_t[mix_idx], path_t[separate_idx], nan_policy=\"omit\"\n",
    "        ).statistic\n",
    "        cur_mix = kruskal(\n",
    "            mixing_t[mix_idx], mixing_t[separate_idx], nan_policy=\"omit\"\n",
    "        ).statistic\n",
    "\n",
    "        cur_d_mix.append(cur_mix - cur_paint)\n",
    "        cur_d_path.append(cur_path - cur_paint)\n",
    "    path_kruskal.append(np.mean(cur_d_path))\n",
    "    mix_kruskal.append(np.mean(cur_d_mix))\n",
    "    path_error.append(sem(cur_d_path))\n",
    "    mix_error.append(sem(cur_d_mix))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(all_rate_intern, mix_kruskal, mix_error, label=\"mixing\")\n",
    "plt.errorbar(all_rate_intern, path_kruskal, path_error, label=\"path\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plot_entropy_game(path_results, paint_results, mixing_results, events=event_list[2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
